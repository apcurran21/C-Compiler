.text
.globl go
go:
pushq %rbx
pushq %rbp
pushq %r12
pushq %r13
pushq %r14
pushq %r15
call _main
popq %r15
popq %r14
popq %r13
popq %r12
popq %rbp
popq %rbx
retq
_vec_ctor:
subq $16, %rsp
_NNNNNN_global_0:
jmp _entry_global_1
_entry_global_1:
movq $7, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 0(%rsp)
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq $0, 0(%r10)
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq $1, 0(%r10)
movq $5, %r10
sarq $1, %r10
movq %r10, %r10
movq $5, %r11
sarq $1, %r11
movq %r10, %r10
imulq %r11, %r10
movq %r10, %r10
salq $1, %r10
movq %r10, %r10
addq $1, %r10
movq %r10, %r10
addq $4, %r10
movq %r10, %rdi
movq $1, %rsi
call allocate
movq %rax, %r8
movq %r8, %r10
addq $8, %r10
movq $5, 0(%r10)
movq %r8, %r10
addq $16, %r10
movq $5, 0(%r10)
movq $2, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
movq 0(%rsp), %r10
movq %r10, %rax
addq $16, %rsp
retq
_memcp32:
subq $16, %rsp
movq %rdi, %r8
movq %rsi, %rcx
movq %rdx, %r11
_NNNNNN_global_3:
jmp _entry_global_4
_entry_global_4:
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdi
sarq $1, %rdi
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %rcx, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $0, %r9
movq %r9, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r8, %r9
addq %r10, %r9
movq 0(%r9), %r9
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $24, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %r9, 0(%r10)
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $0, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdx, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq %rcx, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $1, %r9
movq %r9, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r8, %r9
addq %r10, %r9
movq 0(%r9), %r9
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $1, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $24, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %r9, 0(%r10)
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdx, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq %rcx, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $0, %r9
movq %r9, %r9
imulq $8, %r9
movq %r9, %r9
addq $32, %r9
movq %r8, %r10
addq %r9, %r10
movq 0(%r10), %r9
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $1, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $24, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %r9, 0(%r10)
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdi
sarq $1, %rdi
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $1, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %rcx, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $1, %r9
movq %r9, %r9
imulq $8, %r9
movq %r9, %r9
addq $32, %r9
movq %r8, %r10
addq %r9, %r10
movq 0(%r10), %r9
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rcx
movq %r10, %r10
imulq %rcx, %r10
movq %r10, %rcx
movq $1, %r10
imulq %rcx, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r8
imulq $8, %r8
movq %r8, %r8
addq $24, %r8
movq %r11, %r10
addq %r8, %r10
movq %r9, 0(%r10)
addq $16, %rsp
retq
_memcp23:
subq $16, %rsp
movq %rdi, %r8
movq %rsi, %r11
movq %rdx, %r9
_NNNNNN_global_30:
jmp _entry_global_31
_entry_global_31:
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $0, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $0, %rcx
movq %rcx, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r8, %rcx
addq %r10, %rcx
movq 0(%rcx), %rcx
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rsi
movq %r10, %r10
imulq %rsi, %r10
movq %r10, %rsi
movq $0, %r10
imulq %rsi, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdx, %r10
imulq %rsi, %r10
movq %r10, %rsi
movq %r9, %r10
imulq %rsi, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $32, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %rcx, 0(%r10)
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $0, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $1, %rcx
movq %rcx, %rcx
imulq $8, %rcx
movq %rcx, %rcx
addq $24, %rcx
movq %r8, %r10
addq %rcx, %r10
movq 0(%r10), %rcx
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rsi
sarq $1, %rsi
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rsi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %r9, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $1, %rdi
movq %rdi, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r11, %rdi
addq %r10, %rdi
movq %rcx, 0(%rdi)
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $0, %rcx
movq %rcx, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r8, %rcx
addq %r10, %rcx
movq 0(%rcx), %rcx
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rsi
sarq $1, %rsi
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $1, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rsi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %r9, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r11, %rdi
addq %r10, %rdi
movq %rcx, 0(%rdi)
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $1, %rcx
movq %rcx, %rcx
imulq $8, %rcx
movq %rcx, %rcx
addq $24, %rcx
movq %r8, %r10
addq %rcx, %r10
movq 0(%r10), %rcx
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %rdx, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq %r9, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r8
imulq $8, %r8
movq %r8, %r8
addq $32, %r8
movq %r11, %r10
addq %r8, %r10
movq %rcx, 0(%r10)
addq $16, %rsp
retq
_vec_do_push_back:
subq $24, %rsp
movq %rdi, %r10
movq %r10, 0(%rsp)
movq %rsi, %r11
_NNNNNN_global_57:
jmp _entry_global_58
_entry_global_58:
movq $0, %r10
imulq $8, %r10
movq %r10, %r8
addq $8, %r8
movq 0(%rsp), %r10
movq %r10, %r10
addq %r8, %r10
movq 0(%r10), %r10
movq %r10, 8(%rsp)
movq $1, %r10
imulq $8, %r10
movq %r10, %r8
addq $8, %r8
movq 0(%rsp), %r10
movq %r10, %r10
addq %r8, %r10
movq 0(%r10), %r10
movq %r11, %rdi
movq %r10, %rsi
movq 8(%rsp), %r10
movq %r10, %rdx
movq $_ret_vec_do_push_back_global_60, -8(%rsp)
subq $8, %rsp
jmp _memcp23
_ret_vec_do_push_back_global_60:
movq 8(%rsp), %r10
movq %r10, %r8
addq $1, %r8
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
addq $24, %rsp
retq
_vec_push_back_alloc:
subq $72, %rsp
movq %rdi, %r10
movq %r10, 40(%rsp)
_NNNNNNNNNNNNNNN_global_61:
jmp _entry_global_62
_alloc_new_global_63:
movq $3, %r10
sarq $1, %r10
movq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq %r11, %r11
salq $1, %r11
movq %r11, %r11
addq $1, %r11
movq %r11, %r11
addq $6, %r11
movq %r11, %rdi
movq $1, %rsi
call allocate
movq %rax, %r8
movq %r8, %r10
addq $8, %r10
movq $3, 0(%r10)
movq %r8, %r10
addq $16, %r10
movq $5, 0(%r10)
movq %r8, %r10
addq $24, %r10
movq $5, 0(%r10)
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
addq $72, %rsp
retq
_finish_global_64:
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 48(%rsp), %r11
movq %r11, 0(%r10)
addq $72, %rsp
retq
_inc_global_65:
movq 32(%rsp), %r10
movq %r10, %r10
movq %r10, 32(%rsp)
movq 32(%rsp), %r10
addq $1, %r10
movq %r10, 32(%rsp)
jmp _copy_global_66
_copy_global_66:
movq 8(%rsp), %r10
movq 32(%rsp), %r11
cmpq %r10, %r11
setl %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _do_global_68
jmp _finish_global_64
_do_global_68:
movq $2, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r10
movq %r10, 24(%rsp)
movq 56(%rsp), %r10
movq %r10, %rdi
movq 32(%rsp), %r10
movq %r10, %rsi
movq 24(%rsp), %r10
movq %r10, %rdx
movq $_ret_vec_push_back_alloc_global_71, -8(%rsp)
subq $8, %rsp
jmp _memcp32
_ret_vec_push_back_alloc_global_71:
movq 24(%rsp), %r10
movq %r10, %rdi
movq 48(%rsp), %r10
movq %r10, %rsi
movq 32(%rsp), %r10
movq %r10, %rdx
movq $_ret_vec_push_back_alloc_global_72, -8(%rsp)
subq $8, %rsp
jmp _memcp23
_ret_vec_push_back_alloc_global_72:
jmp _inc_global_65
_extend_global_74:
movq 16(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
sarq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
salq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
salq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
addq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
sarq $1, %r10
movq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq %r11, %r11
salq $1, %r11
movq %r11, %r11
addq $1, %r11
movq %r11, %r11
addq $6, %r11
movq %r11, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 48(%rsp)
movq 48(%rsp), %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, 0(%r11)
movq 48(%rsp), %r10
movq %r10, %r10
addq $16, %r10
movq $5, 0(%r10)
movq 48(%rsp), %r10
movq %r10, %r10
addq $24, %r10
movq $5, 0(%r10)
movq $0, %r10
movq %r10, 32(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
movq %r10, 8(%rsp)
movq 8(%rsp), %r10
sarq $1, %r10
movq %r10, 8(%rsp)
jmp _copy_global_66
_has_space_left_global_76:
addq $72, %rsp
retq
_check_length_global_77:
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r11
movq $0, %r10
imulq $8, %r10
movq %r10, %r8
addq $8, %r8
movq 56(%rsp), %r10
movq %r10, %r10
addq %r8, %r10
movq 0(%r10), %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
sarq $1, %r10
cmpq %r10, %r11
sete %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _extend_global_74
jmp _has_space_left_global_76
_entry_global_62:
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r10
movq %r10, 56(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
andq $1, %r10
cmpq $1, %r10
je _alloc_new_global_63
jmp _check_length_global_77
_main:
subq $56, %rsp
_NNNNNN_global_83:
jmp _entry_global_84
_B6_global_85:
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r10
movq %r10, %rdi
call print
addq $56, %rsp
retq
_B5_global_86:
movq 8(%rsp), %r10
movq %r10, %r10
imulq $2, %r10
movq %r10, %r10
addq $1, %r10
movq %r10, %rdi
call print
movq 16(%rsp), %r10
movq %r10, %rdi
call print
jmp _B4_global_87
_B4_global_87:
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_main_global_89, -8(%rsp)
subq $8, %rsp
jmp _nextfib
_ret_main_global_89:
movq 24(%rsp), %r10
movq %r10, %r10
andq $2097151, %r10
cmpq $0, %r10
sete %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _save_global_90
jmp _B2_global_91
_B2_global_91:
movq $1, %r11
movq 8(%rsp), %r10
addq %r10, %r11
movq %r11, %r10
movq %r10, 8(%rsp)
movq 8(%rsp), %r10
movq 32(%rsp), %r11
cmpq %r10, %r11
setl %r10b
movzbq %r10b, %r10
movq $1, %r11
subq %r10, %r11
movq %r11, %r10
cmpq $1, %r10
je _B3_global_95
jmp _B6_global_85
_B3_global_95:
movq 8(%rsp), %r10
cmpq $10, %r10
setle %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _B5_global_86
jmp _B3_5_global_99
_B3_5_global_99:
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 24(%rsp)
movq 24(%rsp), %r10
subq $1, %r10
movq %r10, 24(%rsp)
movq 24(%rsp), %r10
movq %r10, %r10
andq $33554431, %r10
movq $1, %r11
subq %r10, %r11
cmpq $1, %r11
je _B5_global_86
jmp _B4_global_87
_save_global_90:
movq 0(%rsp), %r10
movq %r10, %rdi
movq $_ret_main_global_104, -8(%rsp)
subq $8, %rsp
jmp _vec_push_back_alloc
_ret_main_global_104:
movq 0(%rsp), %r10
movq %r10, %rdi
movq 16(%rsp), %r10
movq %r10, %rsi
movq $_ret_main_global_105, -8(%rsp)
subq $8, %rsp
jmp _vec_do_push_back
_ret_main_global_105:
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r8
movq %r8, %r8
salq $1, %r8
movq %r8, %r8
addq $1, %r8
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r8
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq %r8, %r10
addq %r11, %r10
movq 0(%r10), %r8
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
movq 40(%rsp), %r10
movq %r10, %rdi
call print
jmp _B2_global_91
_B1_global_107:
movq $5, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 40(%rsp)
movq 40(%rsp), %r10
movq 0(%r10), %r10
movq %r10, %r10
salq $1, %r10
movq %r10, %r10
addq $1, %r10
movq %r10, %rdi
call print
movq $_ret_main_global_108, -8(%rsp)
subq $8, %rsp
jmp _vec_ctor
_ret_main_global_108:
movq %rax, %r10
movq %r10, 0(%rsp)
movq $0, %r10
movq %r10, 8(%rsp)
movq $300000000, %r10
movq %r10, 32(%rsp)
movq $5, %r10
sarq $1, %r10
movq %r10, %r10
movq $5, %r11
sarq $1, %r11
movq %r10, %r10
imulq %r11, %r10
movq %r10, %r10
salq $1, %r10
movq %r10, %r10
addq $1, %r10
movq %r10, %r10
addq $4, %r10
movq %r10, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
addq $8, %r10
movq $5, 0(%r10)
movq 16(%rsp), %r10
movq %r10, %r10
addq $16, %r10
movq $5, 0(%r10)
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_main_global_109, -8(%rsp)
subq $8, %rsp
jmp _initmat
_ret_main_global_109:
jmp _B2_global_91
_entry_global_84:
movq $0, %r10
movq %r10, 24(%rsp)
jmp _B1_global_107
_initmat:
subq $16, %rsp
movq %rdi, %r11
_NNNNNN_global_113:
jmp _entry_global_114
_B1_global_115:
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $0, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $0, %r8
movq %r8, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r11, %r8
addq %r10, %r8
movq $1, 0(%r8)
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $0, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r11, %r8
addq %r10, %r8
movq $3, 0(%r8)
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $1, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $0, %r8
movq %r8, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r11, %r8
addq %r10, %r8
movq $3, 0(%r8)
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $1, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r8
imulq $8, %r8
movq %r8, %r8
addq $24, %r8
movq %r11, %r10
addq %r8, %r10
movq $3, 0(%r10)
addq $16, %rsp
retq
_entry_global_114:
jmp _B1_global_115
_mod10000:
movq %rdi, %r10
_NNNNNNNN_global_126:
jmp _entry_global_127
_mod_global_128:
movq %r10, %r10
subq $10000, %r10
movq %r10, %rdi
movq $_ret_mod10000_global_129, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_mod10000_global_129:
movq %rax, %r10
movq %r10, %rax
retq
_nothing_global_130:
movq %r10, %rax
retq
_entry_global_127:
cmpq $10000, %r10
setge %r11b
movzbq %r11b, %r11
cmpq $1, %r11
je _mod_global_128
jmp _nothing_global_130
_nextfib:
subq $816, %rsp
movq %rdi, %r10
movq %r10, 48(%rsp)
_NNNNNN_global_134:
jmp _entry_global_135
_B3_global_136:
movq 1056(%rsp), %r10
movq %r10, %r10
movq %r10, 24(%rsp)
movq 24(%rsp), %r11
movq 1896(%rsp), %r10
imulq %r10, %r11
movq %r11, 24(%rsp)
movq 1064(%rsp), %r10
movq %r10, %r10
movq %r10, 64(%rsp)
movq 64(%rsp), %r11
movq 1800(%rsp), %r10
imulq %r10, %r11
movq %r11, 64(%rsp)
movq 1056(%rsp), %r10
movq %r10, %r10
movq %r10, 1704(%rsp)
movq 1704(%rsp), %r11
movq 1776(%rsp), %r10
imulq %r10, %r11
movq %r11, 1704(%rsp)
movq 1064(%rsp), %r10
movq %r10, %r10
movq %r10, 1672(%rsp)
movq 1672(%rsp), %r10
movq 1768(%rsp), %r11
imulq %r11, %r10
movq %r10, 1672(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
movq %r10, 1656(%rsp)
movq 1656(%rsp), %r10
movq 1896(%rsp), %r11
imulq %r11, %r10
movq %r10, 1656(%rsp)
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 1568(%rsp)
movq 1568(%rsp), %r11
movq 1800(%rsp), %r10
imulq %r10, %r11
movq %r11, 1568(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
movq %r10, 1608(%rsp)
movq 1608(%rsp), %r11
movq 1776(%rsp), %r10
imulq %r10, %r11
movq %r11, 1608(%rsp)
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 1664(%rsp)
movq 1664(%rsp), %r11
movq 1768(%rsp), %r10
imulq %r10, %r11
movq %r11, 1664(%rsp)
movq 24(%rsp), %r10
movq %r10, %r10
movq %r10, 40(%rsp)
movq 40(%rsp), %r11
movq 64(%rsp), %r10
addq %r10, %r11
movq %r11, 40(%rsp)
movq 1704(%rsp), %r10
movq %r10, %r10
movq %r10, 32(%rsp)
movq 32(%rsp), %r11
movq 1672(%rsp), %r10
addq %r10, %r11
movq %r11, 32(%rsp)
movq 1656(%rsp), %r10
movq %r10, %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
movq 1568(%rsp), %r11
addq %r11, %r10
movq %r10, 16(%rsp)
movq 1608(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r11
movq 1664(%rsp), %r10
addq %r10, %r11
movq %r11, 0(%rsp)
jmp _Bend_global_137
_Bend_global_137:
movq 40(%rsp), %r10
movq %r10, %r10
movq %r10, 40(%rsp)
movq 40(%rsp), %r10
addq $1, %r10
movq %r10, 40(%rsp)
movq 32(%rsp), %r10
movq %r10, %r10
movq %r10, 32(%rsp)
movq 32(%rsp), %r10
addq $1, %r10
movq %r10, 32(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
addq $1, %r10
movq %r10, 16(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
addq $1, %r10
movq %r10, 0(%rsp)
movq 40(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_139, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_139:
movq %rax, %r10
movq %r10, 40(%rsp)
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_140, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_140:
movq %rax, %r10
movq %r10, 32(%rsp)
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_141, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_141:
movq %rax, %r10
movq %r10, 16(%rsp)
movq 0(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_142, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_142:
movq %rax, %r10
movq %r10, 0(%rsp)
movq $0, %r10
movq %r10, 632(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 2448(%rsp)
movq 2448(%rsp), %r10
addq $16, %r10
movq %r10, 2448(%rsp)
movq 2448(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 2432(%rsp)
movq 2432(%rsp), %r10
movq %r10, %r10
movq %r10, 2360(%rsp)
movq 2360(%rsp), %r10
sarq $1, %r10
movq %r10, 2360(%rsp)
movq $1, %r10
movq %r10, 480(%rsp)
movq 2360(%rsp), %r10
movq %r10, %r10
movq %r10, 584(%rsp)
movq 480(%rsp), %r10
movq 584(%rsp), %r11
imulq %r10, %r11
movq %r11, 584(%rsp)
movq 584(%rsp), %r10
movq %r10, %r10
movq %r10, 480(%rsp)
movq $0, %r10
movq %r10, 560(%rsp)
movq 480(%rsp), %r10
movq 560(%rsp), %r11
imulq %r10, %r11
movq %r11, 560(%rsp)
movq 560(%rsp), %r10
movq %r10, %r10
movq %r10, 536(%rsp)
movq 536(%rsp), %r10
movq 632(%rsp), %r11
addq %r11, %r10
movq %r10, 536(%rsp)
movq 536(%rsp), %r10
movq %r10, %r10
movq %r10, 632(%rsp)
movq 632(%rsp), %r10
movq %r10, %r10
movq %r10, 632(%rsp)
movq 632(%rsp), %r10
addq $0, %r10
movq %r10, 632(%rsp)
movq 632(%rsp), %r10
movq %r10, %r10
movq %r10, 472(%rsp)
movq 472(%rsp), %r10
imulq $8, %r10
movq %r10, 472(%rsp)
movq 472(%rsp), %r10
movq %r10, %r10
movq %r10, 472(%rsp)
movq 472(%rsp), %r10
addq $24, %r10
movq %r10, 472(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 592(%rsp)
movq 472(%rsp), %r10
movq 592(%rsp), %r11
addq %r10, %r11
movq %r11, 592(%rsp)
movq 40(%rsp), %r10
movq 592(%rsp), %r11
movq %r10, 0(%r11)
movq $0, %r10
movq %r10, 504(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 512(%rsp)
movq 512(%rsp), %r10
addq $16, %r10
movq %r10, 512(%rsp)
movq 512(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 944(%rsp)
movq 944(%rsp), %r10
movq %r10, %r10
movq %r10, 752(%rsp)
movq 752(%rsp), %r10
sarq $1, %r10
movq %r10, 752(%rsp)
movq $1, %r10
movq %r10, 856(%rsp)
movq 752(%rsp), %r10
movq %r10, %r10
movq %r10, 728(%rsp)
movq 728(%rsp), %r10
movq 856(%rsp), %r11
imulq %r11, %r10
movq %r10, 728(%rsp)
movq 728(%rsp), %r10
movq %r10, %r10
movq %r10, 856(%rsp)
movq $0, %r10
movq %r10, 832(%rsp)
movq 832(%rsp), %r10
movq 856(%rsp), %r11
imulq %r11, %r10
movq %r10, 832(%rsp)
movq 832(%rsp), %r10
movq %r10, %r10
movq %r10, 464(%rsp)
movq 464(%rsp), %r10
movq 504(%rsp), %r11
addq %r11, %r10
movq %r10, 464(%rsp)
movq 464(%rsp), %r10
movq %r10, %r10
movq %r10, 504(%rsp)
movq 504(%rsp), %r10
movq %r10, %r10
movq %r10, 504(%rsp)
movq 504(%rsp), %r10
addq $1, %r10
movq %r10, 504(%rsp)
movq 504(%rsp), %r10
movq %r10, %r10
movq %r10, 760(%rsp)
movq 760(%rsp), %r10
imulq $8, %r10
movq %r10, 760(%rsp)
movq 760(%rsp), %r10
movq %r10, %r10
movq %r10, 760(%rsp)
movq 760(%rsp), %r10
addq $24, %r10
movq %r10, 760(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 664(%rsp)
movq 664(%rsp), %r10
movq 760(%rsp), %r11
addq %r11, %r10
movq %r10, 664(%rsp)
movq 32(%rsp), %r10
movq 664(%rsp), %r11
movq %r10, 0(%r11)
movq $0, %r10
movq %r10, 576(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 640(%rsp)
movq 640(%rsp), %r10
addq $16, %r10
movq %r10, 640(%rsp)
movq 640(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 680(%rsp)
movq 680(%rsp), %r10
movq %r10, %r10
movq %r10, 616(%rsp)
movq 616(%rsp), %r10
sarq $1, %r10
movq %r10, 616(%rsp)
movq $1, %r10
movq %r10, 544(%rsp)
movq 616(%rsp), %r10
movq %r10, %r10
movq %r10, 2688(%rsp)
movq 544(%rsp), %r10
movq 2688(%rsp), %r11
imulq %r10, %r11
movq %r11, 2688(%rsp)
movq 2688(%rsp), %r10
movq %r10, %r10
movq %r10, 544(%rsp)
movq $1, %r10
movq %r10, 488(%rsp)
movq 488(%rsp), %r10
movq 544(%rsp), %r11
imulq %r11, %r10
movq %r10, 488(%rsp)
movq 488(%rsp), %r10
movq %r10, %r10
movq %r10, 528(%rsp)
movq 528(%rsp), %r10
movq 576(%rsp), %r11
addq %r11, %r10
movq %r10, 528(%rsp)
movq 528(%rsp), %r10
movq %r10, %r10
movq %r10, 576(%rsp)
movq 576(%rsp), %r10
movq %r10, %r10
movq %r10, 576(%rsp)
movq 576(%rsp), %r10
addq $0, %r10
movq %r10, 576(%rsp)
movq 576(%rsp), %r10
movq %r10, %r10
movq %r10, 496(%rsp)
movq 496(%rsp), %r10
imulq $8, %r10
movq %r10, 496(%rsp)
movq 496(%rsp), %r10
movq %r10, %r10
movq %r10, 496(%rsp)
movq 496(%rsp), %r10
addq $24, %r10
movq %r10, 496(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 1048(%rsp)
movq 496(%rsp), %r10
movq 1048(%rsp), %r11
addq %r10, %r11
movq %r11, 1048(%rsp)
movq 16(%rsp), %r10
movq 1048(%rsp), %r11
movq %r10, 0(%r11)
movq $0, %r10
movq %r10, 1296(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 600(%rsp)
movq 600(%rsp), %r10
addq $16, %r10
movq %r10, 600(%rsp)
movq 600(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 928(%rsp)
movq 928(%rsp), %r10
movq %r10, %r10
movq %r10, 568(%rsp)
movq 568(%rsp), %r10
sarq $1, %r10
movq %r10, 568(%rsp)
movq $1, %r10
movq %r10, 848(%rsp)
movq 568(%rsp), %r10
movq %r10, %r10
movq %r10, 656(%rsp)
movq 656(%rsp), %r11
movq 848(%rsp), %r10
imulq %r10, %r11
movq %r11, 656(%rsp)
movq 656(%rsp), %r10
movq %r10, %r10
movq %r10, 848(%rsp)
movq $1, %r10
movq %r10, 936(%rsp)
movq 848(%rsp), %r11
movq 936(%rsp), %r10
imulq %r11, %r10
movq %r10, 936(%rsp)
movq 936(%rsp), %r10
movq %r10, %r10
movq %r10, 2008(%rsp)
movq 1296(%rsp), %r11
movq 2008(%rsp), %r10
addq %r11, %r10
movq %r10, 2008(%rsp)
movq 2008(%rsp), %r10
movq %r10, %r10
movq %r10, 1296(%rsp)
movq 1296(%rsp), %r10
movq %r10, %r10
movq %r10, 1296(%rsp)
movq 1296(%rsp), %r10
addq $1, %r10
movq %r10, 1296(%rsp)
movq 1296(%rsp), %r10
movq %r10, %r10
movq %r10, 72(%rsp)
movq 72(%rsp), %r10
imulq $8, %r10
movq %r10, 72(%rsp)
movq 72(%rsp), %r10
movq %r10, %r10
movq %r10, 72(%rsp)
movq 72(%rsp), %r10
addq $24, %r10
movq %r10, 72(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 160(%rsp)
movq 72(%rsp), %r11
movq 160(%rsp), %r10
addq %r11, %r10
movq %r10, 160(%rsp)
movq 0(%rsp), %r10
movq 160(%rsp), %r11
movq %r10, 0(%r11)
addq $816, %rsp
retq
_B1_global_151:
movq $0, %r10
movq %r10, 88(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 96(%rsp)
movq 96(%rsp), %r10
addq $16, %r10
movq %r10, 96(%rsp)
movq 96(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 1288(%rsp)
movq 1288(%rsp), %r10
movq %r10, %r10
movq %r10, 112(%rsp)
movq 112(%rsp), %r10
sarq $1, %r10
movq %r10, 112(%rsp)
movq $1, %r10
movq %r10, 104(%rsp)
movq 112(%rsp), %r10
movq %r10, %r10
movq %r10, 264(%rsp)
movq 104(%rsp), %r11
movq 264(%rsp), %r10
imulq %r11, %r10
movq %r10, 264(%rsp)
movq 264(%rsp), %r10
movq %r10, %r10
movq %r10, 104(%rsp)
movq $0, %r10
movq %r10, 240(%rsp)
movq 104(%rsp), %r10
movq 240(%rsp), %r11
imulq %r10, %r11
movq %r11, 240(%rsp)
movq 240(%rsp), %r10
movq %r10, %r10
movq %r10, 232(%rsp)
movq 88(%rsp), %r10
movq 232(%rsp), %r11
addq %r10, %r11
movq %r11, 232(%rsp)
movq 232(%rsp), %r10
movq %r10, %r10
movq %r10, 88(%rsp)
movq 88(%rsp), %r10
movq %r10, %r10
movq %r10, 88(%rsp)
movq 88(%rsp), %r10
addq $0, %r10
movq %r10, 88(%rsp)
movq 88(%rsp), %r10
movq %r10, %r10
movq %r10, 2200(%rsp)
movq 2200(%rsp), %r10
imulq $8, %r10
movq %r10, 2200(%rsp)
movq 2200(%rsp), %r10
movq %r10, %r10
movq %r10, 2200(%rsp)
movq 2200(%rsp), %r10
addq $24, %r10
movq %r10, 2200(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 1336(%rsp)
movq 1336(%rsp), %r10
movq 2200(%rsp), %r11
addq %r11, %r10
movq %r10, 1336(%rsp)
movq 1336(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 1056(%rsp)
movq $0, %r10
movq %r10, 192(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 176(%rsp)
movq 176(%rsp), %r10
addq $16, %r10
movq %r10, 176(%rsp)
movq 176(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 2984(%rsp)
movq 2984(%rsp), %r10
movq %r10, %r10
movq %r10, 2184(%rsp)
movq 2184(%rsp), %r10
sarq $1, %r10
movq %r10, 2184(%rsp)
movq $1, %r10
movq %r10, 216(%rsp)
movq 2184(%rsp), %r10
movq %r10, %r10
movq %r10, 2176(%rsp)
movq 216(%rsp), %r10
movq 2176(%rsp), %r11
imulq %r10, %r11
movq %r11, 2176(%rsp)
movq 2176(%rsp), %r10
movq %r10, %r10
movq %r10, 216(%rsp)
movq $0, %r10
movq %r10, 2328(%rsp)
movq 216(%rsp), %r10
movq 2328(%rsp), %r11
imulq %r10, %r11
movq %r11, 2328(%rsp)
movq 2328(%rsp), %r10
movq %r10, %r10
movq %r10, 184(%rsp)
movq 184(%rsp), %r11
movq 192(%rsp), %r10
addq %r10, %r11
movq %r11, 184(%rsp)
movq 184(%rsp), %r10
movq %r10, %r10
movq %r10, 192(%rsp)
movq 192(%rsp), %r10
movq %r10, %r10
movq %r10, 192(%rsp)
movq 192(%rsp), %r10
addq $1, %r10
movq %r10, 192(%rsp)
movq 192(%rsp), %r10
movq %r10, %r10
movq %r10, 200(%rsp)
movq 200(%rsp), %r10
imulq $8, %r10
movq %r10, 200(%rsp)
movq 200(%rsp), %r10
movq %r10, %r10
movq %r10, 200(%rsp)
movq 200(%rsp), %r10
addq $24, %r10
movq %r10, 200(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 3048(%rsp)
movq 200(%rsp), %r11
movq 3048(%rsp), %r10
addq %r11, %r10
movq %r10, 3048(%rsp)
movq 3048(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 1064(%rsp)
movq $0, %r10
movq %r10, 336(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 3032(%rsp)
movq 3032(%rsp), %r10
addq $16, %r10
movq %r10, 3032(%rsp)
movq 3032(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 3272(%rsp)
movq 3272(%rsp), %r10
movq %r10, %r10
movq %r10, 3240(%rsp)
movq 3240(%rsp), %r10
sarq $1, %r10
movq %r10, 3240(%rsp)
movq $1, %r10
movq %r10, 424(%rsp)
movq 3240(%rsp), %r10
movq %r10, %r10
movq %r10, 448(%rsp)
movq 424(%rsp), %r10
movq 448(%rsp), %r11
imulq %r10, %r11
movq %r11, 448(%rsp)
movq 448(%rsp), %r10
movq %r10, %r10
movq %r10, 424(%rsp)
movq $1, %r10
movq %r10, 408(%rsp)
movq 408(%rsp), %r11
movq 424(%rsp), %r10
imulq %r10, %r11
movq %r11, 408(%rsp)
movq 408(%rsp), %r10
movq %r10, %r10
movq %r10, 376(%rsp)
movq 336(%rsp), %r11
movq 376(%rsp), %r10
addq %r11, %r10
movq %r10, 376(%rsp)
movq 376(%rsp), %r10
movq %r10, %r10
movq %r10, 336(%rsp)
movq 336(%rsp), %r10
movq %r10, %r10
movq %r10, 336(%rsp)
movq 336(%rsp), %r10
addq $0, %r10
movq %r10, 336(%rsp)
movq 336(%rsp), %r10
movq %r10, %r10
movq %r10, 344(%rsp)
movq 344(%rsp), %r10
imulq $8, %r10
movq %r10, 344(%rsp)
movq 344(%rsp), %r10
movq %r10, %r10
movq %r10, 344(%rsp)
movq 344(%rsp), %r10
addq $24, %r10
movq %r10, 344(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 3128(%rsp)
movq 344(%rsp), %r10
movq 3128(%rsp), %r11
addq %r10, %r11
movq %r11, 3128(%rsp)
movq 3128(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 56(%rsp)
movq $0, %r10
movq %r10, 208(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 1504(%rsp)
movq 1504(%rsp), %r10
addq $16, %r10
movq %r10, 1504(%rsp)
movq 1504(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 1488(%rsp)
movq 1488(%rsp), %r10
movq %r10, %r10
movq %r10, 1456(%rsp)
movq 1456(%rsp), %r10
sarq $1, %r10
movq %r10, 1456(%rsp)
movq $1, %r10
movq %r10, 1400(%rsp)
movq 1456(%rsp), %r10
movq %r10, %r10
movq %r10, 1424(%rsp)
movq 1400(%rsp), %r11
movq 1424(%rsp), %r10
imulq %r11, %r10
movq %r10, 1424(%rsp)
movq 1424(%rsp), %r10
movq %r10, %r10
movq %r10, 1400(%rsp)
movq $1, %r10
movq %r10, 1384(%rsp)
movq 1384(%rsp), %r11
movq 1400(%rsp), %r10
imulq %r10, %r11
movq %r11, 1384(%rsp)
movq 1384(%rsp), %r10
movq %r10, %r10
movq %r10, 1232(%rsp)
movq 208(%rsp), %r11
movq 1232(%rsp), %r10
addq %r11, %r10
movq %r10, 1232(%rsp)
movq 1232(%rsp), %r10
movq %r10, %r10
movq %r10, 208(%rsp)
movq 208(%rsp), %r10
movq %r10, %r10
movq %r10, 208(%rsp)
movq 208(%rsp), %r10
addq $1, %r10
movq %r10, 208(%rsp)
movq 208(%rsp), %r10
movq %r10, %r10
movq %r10, 1128(%rsp)
movq 1128(%rsp), %r10
imulq $8, %r10
movq %r10, 1128(%rsp)
movq 1128(%rsp), %r10
movq %r10, %r10
movq %r10, 1128(%rsp)
movq 1128(%rsp), %r10
addq $24, %r10
movq %r10, 1128(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 1112(%rsp)
movq 1112(%rsp), %r11
movq 1128(%rsp), %r10
addq %r10, %r11
movq %r11, 1112(%rsp)
movq 1112(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 8(%rsp)
movq 1056(%rsp), %r10
movq %r10, %r10
movq %r10, 1056(%rsp)
movq 1056(%rsp), %r10
subq $1, %r10
movq %r10, 1056(%rsp)
movq 1064(%rsp), %r10
movq %r10, %r10
movq %r10, 1064(%rsp)
movq 1064(%rsp), %r10
subq $1, %r10
movq %r10, 1064(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
movq %r10, 56(%rsp)
movq 56(%rsp), %r10
subq $1, %r10
movq %r10, 56(%rsp)
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 8(%rsp)
movq 8(%rsp), %r10
subq $1, %r10
movq %r10, 8(%rsp)
jmp _B2_global_160
_B2_global_160:
movq $0, %r10
movq %r10, 1896(%rsp)
movq $1, %r10
movq %r10, 1776(%rsp)
movq $1, %r10
movq %r10, 1800(%rsp)
movq $1, %r10
movq %r10, 1768(%rsp)
jmp _B3_global_136
_entry_global_135:
jmp _B1_global_151
