.text
.globl go
go:
pushq %rbx
pushq %rbp
pushq %r12
pushq %r13
pushq %r14
pushq %r15
call _main
popq %r15
popq %r14
popq %r13
popq %r12
popq %rbp
popq %rbx
retq
_vec_ctor:
subq $16, %rsp
_NNNNNN_global_0:
jmp _entry_global_1
_entry_global_1:
movq $7, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 0(%rsp)
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq $0, 0(%r10)
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq $1, 0(%r10)
movq $5, %r10
sarq $1, %r10
movq %r10, %r10
movq $5, %r11
sarq $1, %r11
movq %r10, %r10
imulq %r11, %r10
movq %r10, %r10
salq $1, %r10
movq %r10, %r10
addq $1, %r10
movq %r10, %r10
addq $4, %r10
movq %r10, %rdi
movq $1, %rsi
call allocate
movq %rax, %r8
movq %r8, %r10
addq $8, %r10
movq $5, 0(%r10)
movq %r8, %r10
addq $16, %r10
movq $5, 0(%r10)
movq $2, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
movq 0(%rsp), %r10
movq %r10, %rax
addq $16, %rsp
retq
_memcp32:
subq $16, %rsp
movq %rdi, %r8
movq %rsi, %rcx
movq %rdx, %r11
_NNNNNN_global_3:
jmp _entry_global_4
_entry_global_4:
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdi
sarq $1, %rdi
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %rcx, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $0, %r9
movq %r9, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r8, %r9
addq %r10, %r9
movq 0(%r9), %r9
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $24, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %r9, 0(%r10)
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $0, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdx, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq %rcx, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $1, %r9
movq %r9, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r8, %r9
addq %r10, %r9
movq 0(%r9), %r9
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $1, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $24, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %r9, 0(%r10)
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdx, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq %rcx, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $0, %r9
movq %r9, %r9
imulq $8, %r9
movq %r9, %r9
addq $32, %r9
movq %r8, %r10
addq %r9, %r10
movq 0(%r10), %r9
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $1, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $24, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %r9, 0(%r10)
movq $0, %r9
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdi
sarq $1, %rdi
movq %r8, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $1, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %rdi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %rcx, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %r9, %r10
movq %r10, %r9
movq %r9, %r9
addq $1, %r9
movq %r9, %r9
imulq $8, %r9
movq %r9, %r9
addq $32, %r9
movq %r8, %r10
addq %r9, %r10
movq 0(%r10), %r9
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rcx
movq %r10, %r10
imulq %rcx, %r10
movq %r10, %rcx
movq $1, %r10
imulq %rcx, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r8
imulq $8, %r8
movq %r8, %r8
addq $24, %r8
movq %r11, %r10
addq %r8, %r10
movq %r9, 0(%r10)
addq $16, %rsp
retq
_memcp23:
subq $16, %rsp
movq %rdi, %r8
movq %rsi, %r11
movq %rdx, %r9
_NNNNNN_global_30:
jmp _entry_global_31
_entry_global_31:
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $0, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $0, %rcx
movq %rcx, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r8, %rcx
addq %r10, %rcx
movq 0(%rcx), %rcx
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rsi
movq %r10, %r10
imulq %rsi, %r10
movq %r10, %rsi
movq $0, %r10
imulq %rsi, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdx, %r10
imulq %rsi, %r10
movq %r10, %rsi
movq %r9, %r10
imulq %rsi, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %rdi
imulq $8, %rdi
movq %rdi, %rdi
addq $32, %rdi
movq %r11, %r10
addq %rdi, %r10
movq %rcx, 0(%r10)
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $0, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $1, %rcx
movq %rcx, %rcx
imulq $8, %rcx
movq %rcx, %rcx
addq $24, %rcx
movq %r8, %r10
addq %rcx, %r10
movq 0(%r10), %rcx
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rsi
sarq $1, %rsi
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $0, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rsi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %r9, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $1, %rdi
movq %rdi, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r11, %rdi
addq %r10, %rdi
movq %rcx, 0(%rdi)
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $0, %rcx
movq %rcx, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r8, %rcx
addq %r10, %rcx
movq 0(%rcx), %rcx
movq $0, %rdi
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rsi
sarq $1, %rsi
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdx
movq %r10, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq $1, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rsi, %r10
imulq %rdx, %r10
movq %r10, %rdx
movq %r9, %r10
imulq %rdx, %r10
movq %r10, %r10
addq %rdi, %r10
movq %r10, %rdi
movq %rdi, %rdi
addq $0, %rdi
movq %rdi, %r10
imulq $8, %r10
movq %r10, %r10
addq $32, %r10
movq %r11, %rdi
addq %r10, %rdi
movq %rcx, 0(%rdi)
movq $0, %rcx
movq %r8, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %rcx, %r10
movq %r10, %rcx
movq %rcx, %rcx
addq $1, %rcx
movq %rcx, %rcx
imulq $8, %rcx
movq %rcx, %rcx
addq $24, %rcx
movq %r8, %r10
addq %rcx, %r10
movq 0(%r10), %rcx
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %rdx
sarq $1, %rdx
movq %r11, %r10
addq $24, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %rdi
movq %r10, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq $1, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %rdx, %r10
imulq %rdi, %r10
movq %r10, %rdi
movq %r9, %r10
imulq %rdi, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r8
imulq $8, %r8
movq %r8, %r8
addq $32, %r8
movq %r11, %r10
addq %r8, %r10
movq %rcx, 0(%r10)
addq $16, %rsp
retq
_vec_do_push_back:
subq $24, %rsp
movq %rdi, %r10
movq %r10, 0(%rsp)
movq %rsi, %r11
_NNNNNN_global_57:
jmp _entry_global_58
_entry_global_58:
movq $0, %r10
imulq $8, %r10
movq %r10, %r8
addq $8, %r8
movq 0(%rsp), %r10
movq %r10, %r10
addq %r8, %r10
movq 0(%r10), %r10
movq %r10, 8(%rsp)
movq $1, %r10
imulq $8, %r10
movq %r10, %r8
addq $8, %r8
movq 0(%rsp), %r10
movq %r10, %r10
addq %r8, %r10
movq 0(%r10), %r10
movq %r11, %rdi
movq %r10, %rsi
movq 8(%rsp), %r10
movq %r10, %rdx
movq $_ret_vec_do_push_back_global_60, -8(%rsp)
subq $8, %rsp
jmp _memcp23
_ret_vec_do_push_back_global_60:
movq 8(%rsp), %r10
movq %r10, %r8
addq $1, %r8
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
addq $24, %rsp
retq
_vec_push_back_alloc:
subq $72, %rsp
movq %rdi, %r10
movq %r10, 40(%rsp)
_NNNNNNNNNNNNNNN_global_61:
jmp _entry_global_62
_alloc_new_global_63:
movq $3, %r10
sarq $1, %r10
movq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq %r11, %r11
salq $1, %r11
movq %r11, %r11
addq $1, %r11
movq %r11, %r11
addq $6, %r11
movq %r11, %rdi
movq $1, %rsi
call allocate
movq %rax, %r8
movq %r8, %r10
addq $8, %r10
movq $3, 0(%r10)
movq %r8, %r10
addq $16, %r10
movq $5, 0(%r10)
movq %r8, %r10
addq $24, %r10
movq $5, 0(%r10)
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
addq $72, %rsp
retq
_finish_global_64:
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 48(%rsp), %r11
movq %r11, 0(%r10)
addq $72, %rsp
retq
_inc_global_65:
movq 32(%rsp), %r10
movq %r10, %r10
movq %r10, 32(%rsp)
movq 32(%rsp), %r10
addq $1, %r10
movq %r10, 32(%rsp)
jmp _copy_global_66
_copy_global_66:
movq 8(%rsp), %r10
movq 32(%rsp), %r11
cmpq %r10, %r11
setl %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _do_global_68
jmp _finish_global_64
_do_global_68:
movq $2, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r10
movq %r10, 24(%rsp)
movq 56(%rsp), %r10
movq %r10, %rdi
movq 32(%rsp), %r10
movq %r10, %rsi
movq 24(%rsp), %r10
movq %r10, %rdx
movq $_ret_vec_push_back_alloc_global_71, -8(%rsp)
subq $8, %rsp
jmp _memcp32
_ret_vec_push_back_alloc_global_71:
movq 24(%rsp), %r10
movq %r10, %rdi
movq 48(%rsp), %r10
movq %r10, %rsi
movq 32(%rsp), %r10
movq %r10, %rdx
movq $_ret_vec_push_back_alloc_global_72, -8(%rsp)
subq $8, %rsp
jmp _memcp23
_ret_vec_push_back_alloc_global_72:
jmp _inc_global_65
_extend_global_74:
movq 16(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
sarq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
salq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
salq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
addq $1, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
sarq $1, %r10
movq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq %r11, %r11
salq $1, %r11
movq %r11, %r11
addq $1, %r11
movq %r11, %r11
addq $6, %r11
movq %r11, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 48(%rsp)
movq 48(%rsp), %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, 0(%r11)
movq 48(%rsp), %r10
movq %r10, %r10
addq $16, %r10
movq $5, 0(%r10)
movq 48(%rsp), %r10
movq %r10, %r10
addq $24, %r10
movq $5, 0(%r10)
movq $0, %r10
movq %r10, 32(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
movq %r10, 8(%rsp)
movq 8(%rsp), %r10
sarq $1, %r10
movq %r10, 8(%rsp)
jmp _copy_global_66
_has_space_left_global_76:
addq $72, %rsp
retq
_check_length_global_77:
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r11
movq $0, %r10
imulq $8, %r10
movq %r10, %r8
addq $8, %r8
movq 56(%rsp), %r10
movq %r10, %r10
addq %r8, %r10
movq 0(%r10), %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
sarq $1, %r10
cmpq %r10, %r11
sete %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _extend_global_74
jmp _has_space_left_global_76
_entry_global_62:
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r10
movq %r10, 56(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
andq $1, %r10
cmpq $1, %r10
je _alloc_new_global_63
jmp _check_length_global_77
_main:
subq $56, %rsp
_NNNNNN_global_83:
jmp _entry_global_84
_B6_global_85:
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r10
movq %r10, %rdi
call print
addq $56, %rsp
retq
_B5_global_86:
movq 8(%rsp), %r10
movq %r10, %r10
imulq $2, %r10
movq %r10, %r10
addq $1, %r10
movq %r10, %rdi
call print
movq 16(%rsp), %r10
movq %r10, %rdi
call print
jmp _B4_global_87
_B4_global_87:
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_main_global_89, -8(%rsp)
subq $8, %rsp
jmp _nextfib
_ret_main_global_89:
movq 24(%rsp), %r10
movq %r10, %r11
andq $2097151, %r11
cmpq $0, %r11
sete %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _save_global_90
jmp _B2_global_91
_B2_global_91:
movq $1, %r10
movq 8(%rsp), %r11
addq %r11, %r10
movq %r10, %r10
movq %r10, 8(%rsp)
movq 8(%rsp), %r10
movq 32(%rsp), %r11
cmpq %r10, %r11
setl %r10b
movzbq %r10b, %r10
movq $1, %r11
subq %r10, %r11
movq %r11, %r10
cmpq $1, %r10
je _B3_global_95
jmp _B6_global_85
_B3_global_95:
movq 8(%rsp), %r10
cmpq $10, %r10
setle %r10b
movzbq %r10b, %r10
cmpq $1, %r10
je _B5_global_86
jmp _B3_5_global_99
_B3_5_global_99:
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 24(%rsp)
movq 24(%rsp), %r10
subq $1, %r10
movq %r10, 24(%rsp)
movq 24(%rsp), %r10
movq %r10, %r11
andq $33554431, %r11
movq $1, %r10
subq %r11, %r10
cmpq $1, %r10
je _B5_global_86
jmp _B4_global_87
_save_global_90:
movq 0(%rsp), %r10
movq %r10, %rdi
movq $_ret_main_global_104, -8(%rsp)
subq $8, %rsp
jmp _vec_push_back_alloc
_ret_main_global_104:
movq 0(%rsp), %r10
movq %r10, %rdi
movq 16(%rsp), %r10
movq %r10, %rsi
movq $_ret_main_global_105, -8(%rsp)
subq $8, %rsp
jmp _vec_do_push_back
_ret_main_global_105:
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r8
movq %r8, %r8
salq $1, %r8
movq %r8, %r8
addq $1, %r8
movq $0, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 0(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq 0(%r10), %r11
movq $0, %r10
imulq $8, %r10
movq %r10, %r10
addq $8, %r10
movq %r11, %r11
addq %r10, %r11
movq 0(%r11), %r8
movq $1, %r10
imulq $8, %r10
movq %r10, %r11
addq $8, %r11
movq 40(%rsp), %r10
movq %r10, %r10
addq %r11, %r10
movq %r8, 0(%r10)
movq 40(%rsp), %r10
movq %r10, %rdi
call print
jmp _B2_global_91
_B1_global_107:
movq $5, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 40(%rsp)
movq $_ret_main_global_108, -8(%rsp)
subq $8, %rsp
jmp _vec_ctor
_ret_main_global_108:
movq %rax, %r10
movq %r10, 0(%rsp)
movq $0, %r10
movq %r10, 8(%rsp)
movq $300000000, %r10
movq %r10, 32(%rsp)
movq $5, %r10
sarq $1, %r10
movq %r10, %r11
movq $5, %r10
sarq $1, %r10
movq %r11, %r11
imulq %r10, %r11
movq %r11, %r11
salq $1, %r11
movq %r11, %r11
addq $1, %r11
movq %r11, %r11
addq $4, %r11
movq %r11, %rdi
movq $1, %rsi
call allocate
movq %rax, %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
addq $8, %r10
movq $5, 0(%r10)
movq 16(%rsp), %r10
movq %r10, %r10
addq $16, %r10
movq $5, 0(%r10)
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_main_global_109, -8(%rsp)
subq $8, %rsp
jmp _initmat
_ret_main_global_109:
jmp _B2_global_91
_entry_global_84:
movq $0, %r10
movq %r10, 24(%rsp)
jmp _B1_global_107
_initmat:
subq $16, %rsp
movq %rdi, %r11
_NNNNNN_global_113:
jmp _entry_global_114
_B1_global_115:
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $0, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $0, %r8
movq %r8, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r11, %r8
addq %r10, %r8
movq $1, 0(%r8)
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $0, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r11, %r8
addq %r10, %r8
movq $3, 0(%r8)
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $1, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $0, %r8
movq %r8, %r10
imulq $8, %r10
movq %r10, %r10
addq $24, %r10
movq %r11, %r8
addq %r10, %r8
movq $3, 0(%r8)
movq $0, %r8
movq %r11, %r10
addq $16, %r10
movq 0(%r10), %r10
movq %r10, %r10
sarq $1, %r10
movq $1, %r9
movq %r10, %r10
imulq %r9, %r10
movq %r10, %r9
movq $1, %r10
imulq %r9, %r10
movq %r10, %r10
addq %r8, %r10
movq %r10, %r8
movq %r8, %r8
addq $1, %r8
movq %r8, %r8
imulq $8, %r8
movq %r8, %r8
addq $24, %r8
movq %r11, %r10
addq %r8, %r10
movq $3, 0(%r10)
addq $16, %rsp
retq
_entry_global_114:
jmp _B1_global_115
_mod10000:
movq %rdi, %r10
_NNNNNNNN_global_126:
jmp _entry_global_127
_mod_global_128:
movq %r10, %r10
subq $10000, %r10
movq %r10, %rdi
movq $_ret_mod10000_global_129, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_mod10000_global_129:
movq %rax, %r10
movq %r10, %rax
retq
_nothing_global_130:
movq %r10, %rax
retq
_entry_global_127:
cmpq $10000, %r10
setge %r11b
movzbq %r11b, %r11
cmpq $1, %r11
je _mod_global_128
jmp _nothing_global_130
_nextfib:
subq $816, %rsp
movq %rdi, %r10
movq %r10, 48(%rsp)
_NNNNNN_global_134:
jmp _entry_global_135
_B3_global_136:
movq 1088(%rsp), %r10
movq %r10, %r10
movq %r10, 24(%rsp)
movq 24(%rsp), %r11
movq 1408(%rsp), %r10
imulq %r10, %r11
movq %r11, 24(%rsp)
movq 1456(%rsp), %r10
movq %r10, %r10
movq %r10, 64(%rsp)
movq 64(%rsp), %r11
movq 1384(%rsp), %r10
imulq %r10, %r11
movq %r11, 64(%rsp)
movq 1088(%rsp), %r10
movq %r10, %r10
movq %r10, 1304(%rsp)
movq 1304(%rsp), %r11
movq 1336(%rsp), %r10
imulq %r10, %r11
movq %r11, 1304(%rsp)
movq 1456(%rsp), %r10
movq %r10, %r10
movq %r10, 1256(%rsp)
movq 1256(%rsp), %r10
movq 1288(%rsp), %r11
imulq %r11, %r10
movq %r10, 1256(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
movq %r10, 1232(%rsp)
movq 1232(%rsp), %r10
movq 1408(%rsp), %r11
imulq %r11, %r10
movq %r10, 1232(%rsp)
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 1160(%rsp)
movq 1160(%rsp), %r11
movq 1384(%rsp), %r10
imulq %r10, %r11
movq %r11, 1160(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
movq %r10, 1192(%rsp)
movq 1192(%rsp), %r11
movq 1336(%rsp), %r10
imulq %r10, %r11
movq %r11, 1192(%rsp)
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 1216(%rsp)
movq 1216(%rsp), %r11
movq 1288(%rsp), %r10
imulq %r10, %r11
movq %r11, 1216(%rsp)
movq 24(%rsp), %r10
movq %r10, %r10
movq %r10, 40(%rsp)
movq 40(%rsp), %r11
movq 64(%rsp), %r10
addq %r10, %r11
movq %r11, 40(%rsp)
movq 1304(%rsp), %r10
movq %r10, %r10
movq %r10, 32(%rsp)
movq 32(%rsp), %r11
movq 1256(%rsp), %r10
addq %r10, %r11
movq %r11, 32(%rsp)
movq 1232(%rsp), %r10
movq %r10, %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
movq 1160(%rsp), %r11
addq %r11, %r10
movq %r10, 16(%rsp)
movq 1192(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r11
movq 1216(%rsp), %r10
addq %r10, %r11
movq %r11, 0(%rsp)
jmp _Bend_global_137
_Bend_global_137:
movq 40(%rsp), %r10
movq %r10, %r10
movq %r10, 40(%rsp)
movq 40(%rsp), %r10
addq $1, %r10
movq %r10, 40(%rsp)
movq 32(%rsp), %r10
movq %r10, %r10
movq %r10, 32(%rsp)
movq 32(%rsp), %r10
addq $1, %r10
movq %r10, 32(%rsp)
movq 16(%rsp), %r10
movq %r10, %r10
movq %r10, 16(%rsp)
movq 16(%rsp), %r10
addq $1, %r10
movq %r10, 16(%rsp)
movq 0(%rsp), %r10
movq %r10, %r10
movq %r10, 0(%rsp)
movq 0(%rsp), %r10
addq $1, %r10
movq %r10, 0(%rsp)
movq 40(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_139, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_139:
movq %rax, %r10
movq %r10, 40(%rsp)
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_140, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_140:
movq %rax, %r10
movq %r10, 32(%rsp)
movq 16(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_141, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_141:
movq %rax, %r10
movq %r10, 16(%rsp)
movq 0(%rsp), %r10
movq %r10, %rdi
movq $_ret_nextfib_global_142, -8(%rsp)
subq $8, %rsp
jmp _mod10000
_ret_nextfib_global_142:
movq %rax, %r10
movq %r10, 0(%rsp)
movq $0, %r10
movq %r10, 624(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 2136(%rsp)
movq 2136(%rsp), %r10
addq $16, %r10
movq %r10, 2136(%rsp)
movq 2136(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 2064(%rsp)
movq 2064(%rsp), %r10
movq %r10, %r10
movq %r10, 2040(%rsp)
movq 2040(%rsp), %r10
sarq $1, %r10
movq %r10, 2040(%rsp)
movq $1, %r10
movq %r10, 480(%rsp)
movq 2040(%rsp), %r10
movq %r10, %r10
movq %r10, 576(%rsp)
movq 480(%rsp), %r10
movq 576(%rsp), %r11
imulq %r10, %r11
movq %r11, 576(%rsp)
movq 576(%rsp), %r10
movq %r10, %r10
movq %r10, 480(%rsp)
movq $0, %r10
movq %r10, 584(%rsp)
movq 480(%rsp), %r10
movq 584(%rsp), %r11
imulq %r10, %r11
movq %r11, 584(%rsp)
movq 584(%rsp), %r10
movq %r10, %r10
movq %r10, 568(%rsp)
movq 568(%rsp), %r10
movq 624(%rsp), %r11
addq %r11, %r10
movq %r10, 568(%rsp)
movq 568(%rsp), %r10
movq %r10, %r10
movq %r10, 624(%rsp)
movq 624(%rsp), %r10
movq %r10, %r10
movq %r10, 624(%rsp)
movq 624(%rsp), %r10
addq $0, %r10
movq %r10, 624(%rsp)
movq 624(%rsp), %r10
movq %r10, %r10
movq %r10, 456(%rsp)
movq 456(%rsp), %r10
imulq $8, %r10
movq %r10, 456(%rsp)
movq 456(%rsp), %r10
movq %r10, %r10
movq %r10, 456(%rsp)
movq 456(%rsp), %r10
addq $24, %r10
movq %r10, 456(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 592(%rsp)
movq 456(%rsp), %r10
movq 592(%rsp), %r11
addq %r10, %r11
movq %r11, 592(%rsp)
movq 40(%rsp), %r10
movq 592(%rsp), %r11
movq %r10, 0(%r11)
movq $0, %r10
movq %r10, 496(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 504(%rsp)
movq 504(%rsp), %r10
addq $16, %r10
movq %r10, 504(%rsp)
movq 504(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 960(%rsp)
movq 960(%rsp), %r10
movq %r10, %r10
movq %r10, 752(%rsp)
movq 752(%rsp), %r10
sarq $1, %r10
movq %r10, 752(%rsp)
movq $1, %r10
movq %r10, 872(%rsp)
movq 752(%rsp), %r10
movq %r10, %r10
movq %r10, 712(%rsp)
movq 712(%rsp), %r10
movq 872(%rsp), %r11
imulq %r11, %r10
movq %r10, 712(%rsp)
movq 712(%rsp), %r10
movq %r10, %r10
movq %r10, 872(%rsp)
movq $0, %r10
movq %r10, 840(%rsp)
movq 840(%rsp), %r10
movq 872(%rsp), %r11
imulq %r11, %r10
movq %r10, 840(%rsp)
movq 840(%rsp), %r10
movq %r10, %r10
movq %r10, 440(%rsp)
movq 440(%rsp), %r10
movq 496(%rsp), %r11
addq %r11, %r10
movq %r10, 440(%rsp)
movq 440(%rsp), %r10
movq %r10, %r10
movq %r10, 496(%rsp)
movq 496(%rsp), %r10
movq %r10, %r10
movq %r10, 496(%rsp)
movq 496(%rsp), %r10
addq $1, %r10
movq %r10, 496(%rsp)
movq 496(%rsp), %r10
movq %r10, %r10
movq %r10, 760(%rsp)
movq 760(%rsp), %r10
imulq $8, %r10
movq %r10, 760(%rsp)
movq 760(%rsp), %r10
movq %r10, %r10
movq %r10, 760(%rsp)
movq 760(%rsp), %r10
addq $24, %r10
movq %r10, 760(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 672(%rsp)
movq 672(%rsp), %r10
movq 760(%rsp), %r11
addq %r11, %r10
movq %r10, 672(%rsp)
movq 32(%rsp), %r10
movq 672(%rsp), %r11
movq %r10, 0(%r11)
movq $0, %r10
movq %r10, 552(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 640(%rsp)
movq 640(%rsp), %r10
addq $16, %r10
movq %r10, 640(%rsp)
movq 640(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 680(%rsp)
movq 680(%rsp), %r10
movq %r10, %r10
movq %r10, 608(%rsp)
movq 608(%rsp), %r10
sarq $1, %r10
movq %r10, 608(%rsp)
movq $1, %r10
movq %r10, 448(%rsp)
movq 608(%rsp), %r10
movq %r10, %r10
movq %r10, 2328(%rsp)
movq 448(%rsp), %r10
movq 2328(%rsp), %r11
imulq %r10, %r11
movq %r11, 2328(%rsp)
movq 2328(%rsp), %r10
movq %r10, %r10
movq %r10, 448(%rsp)
movq $1, %r10
movq %r10, 464(%rsp)
movq 448(%rsp), %r10
movq 464(%rsp), %r11
imulq %r10, %r11
movq %r11, 464(%rsp)
movq 464(%rsp), %r10
movq %r10, %r10
movq %r10, 528(%rsp)
movq 528(%rsp), %r10
movq 552(%rsp), %r11
addq %r11, %r10
movq %r10, 528(%rsp)
movq 528(%rsp), %r10
movq %r10, %r10
movq %r10, 552(%rsp)
movq 552(%rsp), %r10
movq %r10, %r10
movq %r10, 552(%rsp)
movq 552(%rsp), %r10
addq $0, %r10
movq %r10, 552(%rsp)
movq 552(%rsp), %r10
movq %r10, %r10
movq %r10, 472(%rsp)
movq 472(%rsp), %r10
imulq $8, %r10
movq %r10, 472(%rsp)
movq 472(%rsp), %r10
movq %r10, %r10
movq %r10, 472(%rsp)
movq 472(%rsp), %r10
addq $24, %r10
movq %r10, 472(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 488(%rsp)
movq 472(%rsp), %r10
movq 488(%rsp), %r11
addq %r10, %r11
movq %r11, 488(%rsp)
movq 16(%rsp), %r10
movq 488(%rsp), %r11
movq %r10, 0(%r11)
movq $0, %r10
movq %r10, 1000(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 648(%rsp)
movq 648(%rsp), %r10
addq $16, %r10
movq %r10, 648(%rsp)
movq 648(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 904(%rsp)
movq 904(%rsp), %r10
movq %r10, %r10
movq %r10, 848(%rsp)
movq 848(%rsp), %r10
sarq $1, %r10
movq %r10, 848(%rsp)
movq $1, %r10
movq %r10, 632(%rsp)
movq 848(%rsp), %r10
movq %r10, %r10
movq %r10, 792(%rsp)
movq 632(%rsp), %r11
movq 792(%rsp), %r10
imulq %r11, %r10
movq %r10, 792(%rsp)
movq 792(%rsp), %r10
movq %r10, %r10
movq %r10, 632(%rsp)
movq $1, %r10
movq %r10, 536(%rsp)
movq 536(%rsp), %r11
movq 632(%rsp), %r10
imulq %r10, %r11
movq %r11, 536(%rsp)
movq 536(%rsp), %r10
movq %r10, %r10
movq %r10, 1024(%rsp)
movq 1000(%rsp), %r11
movq 1024(%rsp), %r10
addq %r11, %r10
movq %r10, 1024(%rsp)
movq 1024(%rsp), %r10
movq %r10, %r10
movq %r10, 1000(%rsp)
movq 1000(%rsp), %r10
movq %r10, %r10
movq %r10, 1000(%rsp)
movq 1000(%rsp), %r10
addq $1, %r10
movq %r10, 1000(%rsp)
movq 1000(%rsp), %r10
movq %r10, %r10
movq %r10, 1600(%rsp)
movq 1600(%rsp), %r10
imulq $8, %r10
movq %r10, 1600(%rsp)
movq 1600(%rsp), %r10
movq %r10, %r10
movq %r10, 1600(%rsp)
movq 1600(%rsp), %r10
addq $24, %r10
movq %r10, 1600(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 168(%rsp)
movq 168(%rsp), %r11
movq 1600(%rsp), %r10
addq %r10, %r11
movq %r11, 168(%rsp)
movq 0(%rsp), %r10
movq 168(%rsp), %r11
movq %r10, 0(%r11)
addq $816, %rsp
retq
_B1_global_151:
movq $0, %r10
movq %r10, 152(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 136(%rsp)
movq 136(%rsp), %r10
addq $16, %r10
movq %r10, 136(%rsp)
movq 136(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 184(%rsp)
movq 184(%rsp), %r10
movq %r10, %r10
movq %r10, 200(%rsp)
movq 200(%rsp), %r10
sarq $1, %r10
movq %r10, 200(%rsp)
movq $1, %r10
movq %r10, 144(%rsp)
movq 200(%rsp), %r10
movq %r10, %r10
movq %r10, 224(%rsp)
movq 144(%rsp), %r11
movq 224(%rsp), %r10
imulq %r11, %r10
movq %r10, 224(%rsp)
movq 224(%rsp), %r10
movq %r10, %r10
movq %r10, 144(%rsp)
movq $0, %r10
movq %r10, 256(%rsp)
movq 144(%rsp), %r10
movq 256(%rsp), %r11
imulq %r10, %r11
movq %r11, 256(%rsp)
movq 256(%rsp), %r10
movq %r10, %r10
movq %r10, 240(%rsp)
movq 152(%rsp), %r10
movq 240(%rsp), %r11
addq %r10, %r11
movq %r11, 240(%rsp)
movq 240(%rsp), %r10
movq %r10, %r10
movq %r10, 152(%rsp)
movq 152(%rsp), %r10
movq %r10, %r10
movq %r10, 152(%rsp)
movq 152(%rsp), %r10
addq $0, %r10
movq %r10, 152(%rsp)
movq 152(%rsp), %r10
movq %r10, %r10
movq %r10, 232(%rsp)
movq 232(%rsp), %r10
imulq $8, %r10
movq %r10, 232(%rsp)
movq 232(%rsp), %r10
movq %r10, %r10
movq %r10, 232(%rsp)
movq 232(%rsp), %r10
addq $24, %r10
movq %r10, 232(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 520(%rsp)
movq 232(%rsp), %r10
movq 520(%rsp), %r11
addq %r10, %r11
movq %r11, 520(%rsp)
movq 520(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 1088(%rsp)
movq $0, %r10
movq %r10, 1704(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 80(%rsp)
movq 80(%rsp), %r10
addq $16, %r10
movq %r10, 80(%rsp)
movq 80(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 112(%rsp)
movq 112(%rsp), %r10
movq %r10, %r10
movq %r10, 72(%rsp)
movq 72(%rsp), %r10
sarq $1, %r10
movq %r10, 72(%rsp)
movq $1, %r10
movq %r10, 1664(%rsp)
movq 72(%rsp), %r10
movq %r10, %r10
movq %r10, 1656(%rsp)
movq 1656(%rsp), %r10
movq 1664(%rsp), %r11
imulq %r11, %r10
movq %r10, 1656(%rsp)
movq 1656(%rsp), %r10
movq %r10, %r10
movq %r10, 1664(%rsp)
movq $0, %r10
movq %r10, 1768(%rsp)
movq 1664(%rsp), %r10
movq 1768(%rsp), %r11
imulq %r10, %r11
movq %r11, 1768(%rsp)
movq 1768(%rsp), %r10
movq %r10, %r10
movq %r10, 1728(%rsp)
movq 1704(%rsp), %r11
movq 1728(%rsp), %r10
addq %r11, %r10
movq %r10, 1728(%rsp)
movq 1728(%rsp), %r10
movq %r10, %r10
movq %r10, 1704(%rsp)
movq 1704(%rsp), %r10
movq %r10, %r10
movq %r10, 1704(%rsp)
movq 1704(%rsp), %r10
addq $1, %r10
movq %r10, 1704(%rsp)
movq 1704(%rsp), %r10
movq %r10, %r10
movq %r10, 2792(%rsp)
movq 2792(%rsp), %r10
imulq $8, %r10
movq %r10, 2792(%rsp)
movq 2792(%rsp), %r10
movq %r10, %r10
movq %r10, 2792(%rsp)
movq 2792(%rsp), %r10
addq $24, %r10
movq %r10, 2792(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 2616(%rsp)
movq 2616(%rsp), %r11
movq 2792(%rsp), %r10
addq %r10, %r11
movq %r11, 2616(%rsp)
movq 2616(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 1456(%rsp)
movq $0, %r10
movq %r10, 416(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 2584(%rsp)
movq 2584(%rsp), %r10
addq $16, %r10
movq %r10, 2584(%rsp)
movq 2584(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 3176(%rsp)
movq 3176(%rsp), %r10
movq %r10, %r10
movq %r10, 3144(%rsp)
movq 3144(%rsp), %r10
sarq $1, %r10
movq %r10, 3144(%rsp)
movq $1, %r10
movq %r10, 1568(%rsp)
movq 3144(%rsp), %r10
movq %r10, %r10
movq %r10, 104(%rsp)
movq 104(%rsp), %r10
movq 1568(%rsp), %r11
imulq %r11, %r10
movq %r10, 104(%rsp)
movq 104(%rsp), %r10
movq %r10, %r10
movq %r10, 1568(%rsp)
movq $1, %r10
movq %r10, 3256(%rsp)
movq 1568(%rsp), %r11
movq 3256(%rsp), %r10
imulq %r11, %r10
movq %r10, 3256(%rsp)
movq 3256(%rsp), %r10
movq %r10, %r10
movq %r10, 3224(%rsp)
movq 416(%rsp), %r11
movq 3224(%rsp), %r10
addq %r11, %r10
movq %r10, 3224(%rsp)
movq 3224(%rsp), %r10
movq %r10, %r10
movq %r10, 416(%rsp)
movq 416(%rsp), %r10
movq %r10, %r10
movq %r10, 416(%rsp)
movq 416(%rsp), %r10
addq $0, %r10
movq %r10, 416(%rsp)
movq 416(%rsp), %r10
movq %r10, %r10
movq %r10, 352(%rsp)
movq 352(%rsp), %r10
imulq $8, %r10
movq %r10, 352(%rsp)
movq 352(%rsp), %r10
movq %r10, %r10
movq %r10, 352(%rsp)
movq 352(%rsp), %r10
addq $24, %r10
movq %r10, 352(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 336(%rsp)
movq 336(%rsp), %r10
movq 352(%rsp), %r11
addq %r11, %r10
movq %r10, 336(%rsp)
movq 336(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 56(%rsp)
movq $0, %r10
movq %r10, 328(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 88(%rsp)
movq 88(%rsp), %r10
addq $16, %r10
movq %r10, 88(%rsp)
movq 88(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 1928(%rsp)
movq 1928(%rsp), %r10
movq %r10, %r10
movq %r10, 1896(%rsp)
movq 1896(%rsp), %r10
sarq $1, %r10
movq %r10, 1896(%rsp)
movq $1, %r10
movq %r10, 1840(%rsp)
movq 1896(%rsp), %r10
movq %r10, %r10
movq %r10, 1864(%rsp)
movq 1840(%rsp), %r11
movq 1864(%rsp), %r10
imulq %r11, %r10
movq %r10, 1864(%rsp)
movq 1864(%rsp), %r10
movq %r10, %r10
movq %r10, 1840(%rsp)
movq $1, %r10
movq %r10, 1824(%rsp)
movq 1824(%rsp), %r11
movq 1840(%rsp), %r10
imulq %r10, %r11
movq %r11, 1824(%rsp)
movq 1824(%rsp), %r10
movq %r10, %r10
movq %r10, 1792(%rsp)
movq 328(%rsp), %r11
movq 1792(%rsp), %r10
addq %r11, %r10
movq %r10, 1792(%rsp)
movq 1792(%rsp), %r10
movq %r10, %r10
movq %r10, 328(%rsp)
movq 328(%rsp), %r10
movq %r10, %r10
movq %r10, 328(%rsp)
movq 328(%rsp), %r10
addq $1, %r10
movq %r10, 328(%rsp)
movq 328(%rsp), %r10
movq %r10, %r10
movq %r10, 3040(%rsp)
movq 3040(%rsp), %r10
imulq $8, %r10
movq %r10, 3040(%rsp)
movq 3040(%rsp), %r10
movq %r10, %r10
movq %r10, 3040(%rsp)
movq 3040(%rsp), %r10
addq $24, %r10
movq %r10, 3040(%rsp)
movq 48(%rsp), %r10
movq %r10, %r10
movq %r10, 3024(%rsp)
movq 3024(%rsp), %r11
movq 3040(%rsp), %r10
addq %r10, %r11
movq %r11, 3024(%rsp)
movq 3024(%rsp), %r10
movq 0(%r10), %r10
movq %r10, 8(%rsp)
movq 1088(%rsp), %r10
movq %r10, %r10
movq %r10, 1088(%rsp)
movq 1088(%rsp), %r10
subq $1, %r10
movq %r10, 1088(%rsp)
movq 1456(%rsp), %r10
movq %r10, %r10
movq %r10, 1456(%rsp)
movq 1456(%rsp), %r10
subq $1, %r10
movq %r10, 1456(%rsp)
movq 56(%rsp), %r10
movq %r10, %r10
movq %r10, 56(%rsp)
movq 56(%rsp), %r10
subq $1, %r10
movq %r10, 56(%rsp)
movq 8(%rsp), %r10
movq %r10, %r10
movq %r10, 8(%rsp)
movq 8(%rsp), %r10
subq $1, %r10
movq %r10, 8(%rsp)
jmp _B2_global_160
_B2_global_160:
movq $0, %r10
movq %r10, 1408(%rsp)
movq $1, %r10
movq %r10, 1336(%rsp)
movq $1, %r10
movq %r10, 1384(%rsp)
movq $1, %r10
movq %r10, 1288(%rsp)
jmp _B3_global_136
_entry_global_135:
jmp _B1_global_151
